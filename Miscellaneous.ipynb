{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN7S8ZmWRjtPAxFXwF9bvNM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VSJpoHRXHdXy","executionInfo":{"status":"ok","timestamp":1702621005138,"user_tz":300,"elapsed":31949,"user":{"displayName":"Abhignya","userId":"05737312112655230415"}},"outputId":"50d144ba-1cad-45b1-927d-521462fd886c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import numpy as np\n","import pandas as pd\n","\n","import os\n","import time\n","import gc\n","\n","from sklearn.model_selection import KFold, StratifiedKFold\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics import mean_squared_error, accuracy_score, roc_auc_score, log_loss, f1_score, precision_score, recall_score\n","from sklearn.ensemble import ExtraTreesClassifier\n","\n","from lightgbm import LGBMClassifier\n","\n","import random\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","from tqdm import tqdm\n","from keras.preprocessing import text, sequence\n","import torch\n","from torch import nn\n","from torch.utils import data\n","from torch.nn import functional as F"]},{"cell_type":"code","source":["import pickle\n","from sklearn.model_selection import StratifiedKFold"],"metadata":{"id":"cA4U0z-gKQ8J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from xgboost import XGBClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn import metrics"],"metadata":{"id":"kWoB5d3mKOjB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_model(data_loader, model, optimizer, device):\n","  \"\"\"\n","  This function does training for one epoch\n","  :param data_loader: this is the pytorch dataloader\n","  :param model: pytorch model\n","  :param optimizer: optimizer, for e.g. adam, sgd, etc\n","  :param device: cuda/cpu\n","  \"\"\"\n","  # put the model in train mode\n","  model.train()\n","  # scheduler = get_scheduler(optimizer, 'CosineAnnealingWarmRestarts')\n","  # go over every batch of data in data loader\n","  for data in tqdm(data_loader):\n","    # remember, we have image and targets\n","    # in our dataset class\n","    inputs = data[\"X\"]\n","    targets = data[\"targets\"]\n","\n","    # move inputs/targets to cuda/cpu device\n","    inputs = inputs.to(device, dtype=torch.float)\n","    targets = targets.to(device, dtype=torch.float)\n","\n","    # zero grad the optimizer\n","    optimizer.zero_grad()\n","    #do the forward step of model\n","    outputs = model(inputs)\n","    # calculate loss\n","\n","    loss = nn.CrossEntropyLoss()(outputs,targets.long())\n","    # backward step the loss\n","    loss.backward()\n","    # step optimizer\n","    optimizer.step()\n","    # if you have a scheduler, you either need to\n","    # step it here or you have to step it after\n","    # the epoch. here, we are not using any learning\n","    # rate scheduler\n","  # scheduler.step()\n","\n","def evaluate_model(data_loader, model, device):\n","  \"\"\"\n","  This function does evaluation for one epoch\n","  :param data_loader: this is the pytorch dataloader\n","  :param model: pytorch model\n","  :param device: cuda/cpu\n","  \"\"\"\n","  # put model in evaluation mode\n","  model.eval()\n","\n","  # init lists to store targets and outputs\n","  final_targets = []\n","  final_outputs = []\n","\n","  # we use no_grad context\n","  with torch.no_grad():\n","    for data in tqdm(data_loader):\n","      inputs = data[\"X\"]\n","      targets = data[\"targets\"]\n","      inputs = inputs.to(device, dtype=torch.float)\n","      targets = targets.to(device, dtype=torch.float)\n","\n","      # do the forward step to generate prediction\n","      output = model(inputs)\n","\n","      # convert targets and outputs to lists\n","      targets = targets.detach().cpu().numpy().tolist()\n","      output = output.detach().cpu().numpy().tolist()\n","\n","      # extend the original list\n","      final_targets.extend(targets)\n","      final_outputs.extend(output)\n","\n","  # return final output and final targets\n","  return final_outputs, final_targets\n","\n","import os\n","def save_checkpoint(model, optimizer, path):\n","    if not os.path.exists(os.path.dirname(path)):\n","        print(\"Creating directories on path: `{}`\".format(path))\n","        os.makedirs(os.path.dirname(path))\n","\n","    torch.save({\n","        \"model_state_dict\": model.state_dict(),\n","        \"optimizer_state_dict\": optimizer.state_dict(),\n","    }, path)\n","\n","\n","def load_checkpoint(model, path):\n","    checkpoint = torch.load(path)\n","\n","    model.load_state_dict(checkpoint[\"model_state_dict\"])\n","\n","    optimizer = torch.optim.Adam(model.parameters())\n","    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n","\n","    return model, optimizer\n","\n","\n","def save_model(model, path):\n","  if not os.path.exists(os.path.dirname(path)):\n","      print(\"Creating directories on path: `{}`\".format(path))\n","      os.makedirs(os.path.dirname(path))\n","\n","  torch.save({\n","      \"model_state_dict\": model.state_dict(),\n","  }, path)\n","\n","\n","def load_model(model, path):\n","  restore_dict = torch.load(path)\n","\n","  model.load_state_dict(restore_dict[\"model_state_dict\"])\n","  model.eval()\n","\n","  return model\n","\n","from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n","\n","def get_scheduler(optimizer, scheduler):\n","    if scheduler=='ReduceLROnPlateau':\n","        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=4, verbose=True, eps=1e-6)\n","    elif scheduler=='CosineAnnealingLR':\n","        scheduler = CosineAnnealingLR(optimizer, T_max=10, eta_min=1e-6, last_epoch=-1)\n","    elif scheduler=='CosineAnnealingWarmRestarts':\n","        scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=1, eta_min=1e-6, last_epoch=-1)\n","    return scheduler"],"metadata":{"id":"QA5T0BlmH4B_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["LSTM_UNITS = 128\n","GRU_UNITS = 128\n","DENSE_HIDDEN_UNITS = 4 * LSTM_UNITS\n","MAX_LEN = 100"],"metadata":{"id":"9xg5LQO0Hy58"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class NeuralNet(nn.Module):\n","    def __init__(self, input_shape, num_aux_targets):\n","        super(NeuralNet, self).__init__()\n","        self.lstm = nn.LSTM(input_shape, LSTM_UNITS, bidirectional=True, batch_first=True)\n","        self.gru = nn.GRU(input_shape, GRU_UNITS, bidirectional=True, batch_first=True)\n","\n","        self.linear1 = nn.Linear(LSTM_UNITS*2, DENSE_HIDDEN_UNITS)\n","        self.linear2 = nn.Linear(GRU_UNITS*2, DENSE_HIDDEN_UNITS)\n","\n","        self.attention = nn.Sequential(\n","            nn.Linear(DENSE_HIDDEN_UNITS, 256),\n","            nn.Tanh(),\n","            nn.Linear(256, 1),\n","            nn.Softmax(dim=1)\n","        )\n","\n","\n","        self.linear_out = nn.Linear(DENSE_HIDDEN_UNITS, num_aux_targets)\n","        # self.linear_aux_out = nn.Linear(DENSE_HIDDEN_UNITS, num_aux_targets)\n","\n","    def forward(self, x):\n","        x = x.view((-1,1,100))\n","        h_lstm, _ = self.lstm(x)\n","        h_gru, _ = self.gru(x)\n","\n","        h_lstm = h_lstm.squeeze()\n","        h_gru = h_gru.squeeze()\n","\n","        # global average pooling\n","        # avg_pool = torch.mean(h_lstm2, 1)\n","        # global max pooling\n","        # max_pool, _ = torch.max(h_lstm2, 1)\n","\n","        # h_conc = torch.cat((max_pool, avg_pool), 1)\n","        h_conc_linear1  = F.relu(self.linear1(h_lstm))\n","        h_conc_linear2  = F.relu(self.linear2(h_gru))\n","\n","        hidden = (h_conc_linear1 + h_conc_linear2)/2\n","\n","        weights = self.attention(hidden)\n","\n","        context_vector = weights * hidden\n","\n","        # print(context_vector.shape)\n","        # print(weights.shape)\n","        # print(hidden.shape)\n","\n","        results = self.linear_out(context_vector)\n","\n","        return nn.Softmax(dim=1)(results)"],"metadata":{"id":"YQbL7GZfH6qg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["models_nn = [\n","             '/content/drive/MyDrive/models/model_fold0_33.pth',\n","             '/content/drive/MyDrive/models/model_fold1_48.pth',\n","             '/content/drive/MyDrive/models/model_fold2_49.pth',\n","             '/content/drive/MyDrive/models/model_fold3_39.pth',\n","             '/content/drive/MyDrive/models/model_fold4_38.pth'\n","\n","]\n","models_xgb = [\n","              '/content/drive/MyDrive/models/xgb_fold0.b5',\n","              '/content/drive/MyDrive/models/xgb_fold1.b5',\n","              '/content/drive/MyDrive/models/xgb_fold2.b5',\n","              '/content/drive/MyDrive/models/xgb_fold3.b5',\n","              '/content/drive/MyDrive/models/xgb_fold4.b5'\n","]\n","\n","models_lgbm = [\n","               '/content/drive/MyDrive/models/lgbm_fold0.b5',\n","               '/content/drive/MyDrive/models/lgbm_fold1.b5',\n","               '/content/drive/MyDrive/models/lgbm_fold2.b5',\n","               '/content/drive/MyDrive/models/lgbm_fold3.b5',\n","               '/content/drive/MyDrive/models/lgbm_fold4.b5'\n","]"],"metadata":{"id":"fGOJ132VHfqd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","\n","trainable_params = 0\n","\n","\n","for model_nn, model_lgbm, model_xgb in zip(models_nn, models_lgbm, models_xgb):\n","  model = NeuralNet(100, 9)\n","  model, _ = load_checkpoint(model, model_nn)\n","  model_xgb = pickle.load(open(model_xgb, 'rb'))\n","  model_lgbm = pickle.load(open(model_lgbm, 'rb'))\n","  trainable_params += sum(p.numel() for p in model.parameters() if p.requires_grad)\n","print(f\"Number of trainable parameters: {trainable_params/5}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q4jsT8A3JMuQ","executionInfo":{"status":"ok","timestamp":1702622352778,"user_tz":300,"elapsed":725,"user":{"displayName":"Abhignya","userId":"05737312112655230415"}},"outputId":"380e6ef1-8221-4119-f210-1e7b51d90da8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of trainable parameters: 811530.0\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"BCVGU9r6JfsR"},"execution_count":null,"outputs":[]}]}